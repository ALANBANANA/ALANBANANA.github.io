# 第一章 绪论

## 1.1 机器学习 是什么； 为什么； 怎么样

定义： 计算机通过经验，积累经验，对心得情况做出有效的决策测，利用经验改善自身的性能

是什么： 研究关于“学习算法”（一类能从数据种发现潜在规律的算法）的学科

我的目的：AI4S，数据驱动CFD

经验数据->学习算法发掘出数据的内在规律(模型)->面对新的情况时->给出新的判断

## 1.2 假设空间和版本空间

例如：某地区近几年的房价和学校数量数据，希望由收集到的数据训练出学校数量预测房价的模型，数据如下

| 年份 | 学校数量 |     房价     |
| :--: | :------: | :----------: |
| 2020 |    1     | 1 万/${m^2}$ |
| 2021 |    2     | 4 万/${m^2}$ |

1. **假设空间**: 一元一次函数， 算法：线性回归， 模型：$y = 3x-2$
2. **假设空间**: 一元二次函数，算法：多项式回归， 模型: $y=x^2$

所有能够拟合训练集的模型(假设)构成的集合称为**"版本空间"**， 一般来说假设空间要**大于**版本空间

同理西瓜书上面的案例的分类问题：

| 编号 | 色泽 | 根缔 | 敲声 | 是否为好瓜 |
| :--: | :--: | :--: | :--: | :--------: |
|  1   | 青绿 | 蜷缩 | 浊响 |     是     |
|  2   | 乌黑 | 蜷缩 | 浊响 |     是     |
|  3   | 青绿 | 硬挺 | 清脆 |     否     |
|  4   | 乌黑 | 稍蜷 | 沉闷 |     否     |

根据色泽、根缔、敲声来分别决定西瓜是否为好瓜

## 1.3基本术语

1. **样本**是对一个事件或者对象的描述

2. 上述西瓜的好坏分辨案例种，色泽、根缔和敲声都是**特征**，其中在这个案例中有三个特征，即有三个**维度**=属性

3. 相关概念：x = (青绿；根缔；敲声)种，**“;”** 分隔表示这个向量为列向量，而 **“,”** 分隔时表示为行向量

4. 上面的案例中的西瓜是“好瓜”or“坏瓜”， 即y=好瓜/坏瓜即为**标记**，英语即为**"label"**

5. 样本空间: 特征向量表示，表示特征向量所在的位置，有向量便会有向量所在的空间"$X$"

6. 标记空间: 标记(label)所在的空间或者说输出的空间， "$Y$"

7. 根据标记的取值类型，一般讲机器学习任务分为两类

   7.1. 当标记取值为**离散型**时，任务为**分类**

   7.2. 当标记取值为**连续型**时， 任务为**回归**

8. 根据是否有用到标记信息即有无**y**，可以讲机器学习分为**监督式学习**和**无监督式学习**

9. 无论是分类还是回归，其实最终都是回归到数学上的: $y =f(x)$

10. **数据集**实际就是一个集合， 集合 $D = \left\{x_1, x_2, x_3,..., x_i\right\}$表示有i个样本， 而类似上述的房价预测和西瓜案例分别有2和4个样本

11. **模型**=学习器，数据背后的推动因素是真相和真实， 所以模型是将真实的推动因素假设为了可解释的数学所以模型是假设

12. **泛化**即根据已知对未知尽可能准确的判断，因此对事物判断的准确才是判断一个模型好坏的关键，为泛化能力

13. 数据需要时**独立同分布**的

## 1.4归纳偏好

基于模型在测试集上的表现来评判那模型之间的优劣

**NFL No Lunch Free**: 没有好的算法，只有解决问题的轻重之分，哪个算法在测试上表现好，哪个算法就更好

## 1.5 数据决定上限，算法可以无限接近

1. 数据决定模型效果的上限：数据是指从数据量和特征工程的角度。数据量越大模型效果越好；从特征工程角度来看，特征数值化越合理，特征手机越权越细致，模型效果越好
2. 算法可以是数据无限接近这个上限：数据相关的工作已经充分准备，套用算法从数据种学习规律，不同算法效果有高低之分，效果越好越逼近上限





